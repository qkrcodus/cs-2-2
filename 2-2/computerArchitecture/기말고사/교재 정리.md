cpu 가 메모리에 접근하는 경우 1. 명령어 읽기 2. load store 
 
 **메모리 계층 구조, 그 중 캐시에 대해 알아보자**
##### 메모리 계층 구조
계층적 메모리 사용 이유? average memory access 시간을 줄이기 위해서
register - cache - memory

- 시간적 지역성 : 최근에 접근한 메모리를 곧 다시 접근할 가능성 높다 => 이를 위해 만든게 ==cache== ( 이유!  cpu 가 요청한 주소로부터 cache block size 만큼을 읽어와 cache 에 저장한다.  )
- 공간적 지역성 : 특정 메모리 위치에 접근하면 그 주변 메모리 위치도 곧 접근할 가능성 높다 
- 비용 : 최상위 계층일수록 비싸다.

##### 프로그램이 실행되면?
1. 프로그램의 코드가 RAM 으로 로드되며, 데이터의 메모리 주소가 정해진다. 
2. CPU 는 PC 를 사용하여 다음 instruction의 메모리 주소를 추적한다.
3. 프로그램이 실행되면, CPU 는  instruction 을 읽고 CPU가 instruction을 처리하는 과정 중 instruction decode 단계에서 필요한 data 를 읽는다. 

< 요약 >CPU 가 주기억장치에 저장된 data 나 instruction 을 Memory 주소를 통해 요청한다. 

###### CPU가 요청하는 memory 주소는 byte 단위기 때문에 cache는 이를 자신에 맞게 해석해야 한다. 
( 예 )
CPU 는 주소 0x1003에서 1바이트의 메모리를 읽으려 한다. 
캐시는 이 바이트가 포함된 캐시 라인 전체를 저장한다. 그래서 나온게 BYTE OFFSET, INDEX, TAG

- cache block size 가 4바이트면 그 중 어떤 값을 cpu가 요청한건지 알아야 하므로,  BO 2 비트
- cache line 이 256 줄이면, index는 8 비트
- 나머지가 tag

##### 캐시의 기본
- 데이터가 캐시에 있는지 어떻게 알 수 있는가?
- 캐시 속 데이터를 어떻게 찾을 것인가?

( 예 )
cache block size : 64 바이트 ( BO 6 비트)
cahce line : 256 개 ( index 8 비트)
메모리 주소 : 0x12345678 (32비트 cpu)

- CPU 는 ox12345678 주소에서 데이터를 읽으려한다. 
- 캐시는 index 랑 일치하는 캐시 라인으로가 tag를 비교한다. tag 일치하면 캐시 hit 
- hit 이면 bo 이용해서 캐시 라인의 특정 바이트를 읽는다. 

cf > 32 bit cpu 64 bit cpu
CPU  가 접근할 수 있는 메모리 크기 

( 예 )
64 비트 cpu 에서 BO 3 bit , index 11 bit 면 tag는 50 bit

##### Hit 과 Miss , AAT
메모리 계층 구조를 만든 이유는 성능 향상이다. 

average access time = hit time + miss rate x miss penalty
-  hit time : 상위 계층 접근하는데 걸린 시간과 접근이 실패인지 적중인지 결정하는데 걸린 시간 ( miss 여도 존재 )
- miss penalty : miss 일 때 하위 계층에서 블록을 가져와서 상위 계층 block과 교체하는데 걸린 시간 + 해당 블록을 CPU에게 보낸 시간

##### Cache miss 3가지
1. cold start
2. capacity
3. conflict
##### CPU 속 cache를 어떻게 만들까?
고려할 점 3가지
1. data placement
2. data replacement
3. write policy

1. data placement
memory 에서 data 가져와서 cache 속 어디에 적을까?  

2.  data replacement
cache 에서 같은 위치로 매핑 된 memory를 어떻게 다룰까? 어떻게 쫓아낼까?

3. write policy
write 요청을 받았을 때, cpu 는 memory에 쓰겠다는거다. cache가 모았다가 쓰는 방법, 요청 올 때마다 쓰는 방법이 있다.

##### 1. data placement
1. direct mapped
2. fully associative
3. n-way set associative  ( 요즘 많이 쓰임 )
##### a )Direct Mapped Cache 의 단점
![[Pasted image 20241202144258.png]]
mod연산으로 cache에 매핑한 것 이 아니라면? spactial locality 때문에 한 번 접근 한 메모리 주변 메모리에 다시 접근할 가능성이 높은데, cache miss 발생 확률이 올라간다.

캐시 있는지 확인 방법 : index 비교, tag 비교
Data엔 실제 메모리 데이터가 바이트 단위로 저장된다. 

![[Pasted image 20241202211151.png]]
(예시) 32비트 CPU

CPU가 `0x12345678` 주소에서 데이터를 읽으려 요청한다.

-  direct map의 block size 
![[Pasted image 20241202215349.png]]


##### b) n-way set associative cache 의 단점과 장점
direct mapped cache 의 단점은 conflict miss 때문. 이를 해결하기 위해 
data가 매핑되는 캐시 entry내 특정 위치 중 하나에 데이터를 저장하기에 conflict miss 가 날 가능성이 줄어든다. 

다만, n의 값이 너무 커지면 n개의 comparator n개의 mux 가 추가되고 n 번의 비교를 해야하므로 hit time이 늘어나고 하드웨어적으로 복잡해진다. 

##### c) fully set associative cache 단점과 장점
conflict miss 가 날 이유가 없다. miss가 난다면 capacity miss 다. 
comparator 와mux 가 여러 개 추가되고 여러번의 비교를 해야하므로 hit time이 늘어나고 하드웨어적으로 복잡해진다. 

direct vs full
- hit time , miss rate
##### 캐시 만들때 고려할 3가지
1. data placement 2. data replacement 3. write policy

##### 캐시 성능을 올리기 위한 방법 2가지
1. victim cache 2. prefetching
##### victim cache
direct mapped cache 에 이용. 
conflict miss 가 발생하면 캐시속 dirty bit 가 1이면 쫓겨난 캐시 데이터가 victim  cache에 적히고, 메모리에 덮어쓰고 저장
dirty bit 0이면 덮어 쓰지 않는다. . 
캐시 같은 레벨에 victim fully associated cache 둔다.
victim 에 데이터 넣으면 L1 hit이랑 같은 기능
##### prefetching
공간적 지역성 있는 데이터엔 좋으나
pollution 발생 가능. 캐시가 아닌 prefetching buffer에 데이터를 담을 수 있다. 
buffer를 lookup 해야함 단점
과하게 prefetching 하면, wasted memory
적절한 시간에 해야한다. 

##### 메모리 계층 중 virtual memory
컴퓨터가 하나의 프로세스 하나의 애플리케이션만 돌아간다면 필요없다. 
하지만 우린 한글, 카카오톡, 사파리 등 여러 프로그램을 동시에 사용하기에 별도의 프로세스가 컴퓨터 즉, 하드웨어에서 동작한다.

코딩할 때 나만의 메모리를 갖는다 생각한다. 다른 애랑 메모리를 공유하고 있다고 생각하지 않는다. 

프로세스는 내가 메모리 전체 다 쓰고 있다고 착각한다. 

os는 프로세스에게 virtual memroy를 갖게 한다. 프로세서는 가상 메모리에 각각 돌아간다.

이 가상 메모리를 실제 메모리에 매핑해주는 역할을 os가 한다. 

os 뿐만 아니라 하드웨어도 vm을 지원한다.

virtual memory 합한게 physical memory보다 더 클 수 있다. 

##### address translation이 필요한 이유
1개의 하드웨어 위에 여러 process가 돌아간다. 한글 , 카카오톡 , 스포티파이 등 동시에 사용가능하다.
각 process 는 컴퓨터의 메모리를 전부 사용하고 있다는 착각이 들게 virtual memory를 각각 사용한다.
이를 physical memory로 매핑시켜주고, 매핑된 결과 paging table을 메모리에 올린다. 

주메모리(ram) : 전원 꺼지면 데이터 사라짐
보조메모리(disk storage) : 전원 꺼져도 데이터 유지

##### 가상 메모리를 요청하기부터 페이지 테이블 갱신하기까지 과정
컴퓨터가 켜지면 os와 프로그램이 보조메모리에서 주메모리로 로드
컴퓨터는 주메모리 ram을 diskstorage의 캐시처럼 사용한다.
virtual memroy는 보조메모리안에 있다. 

- 시작
CPU 가 가상 주소를 이용하여 우선 TLB를 확인 
TLB엔 valid dirty page# frame# 있다.
가상 주소의 page#랑 TLB의 page#가 같은지 확인
그 엔트리의 valid가 1인지 확인 만약 맞다면 TLB에 매핑된 frame#+pageoffset으로 실제 주소 파악 후 tag,index,bo로 구분해서 데이터 찾으러 감

가상 주소의 page#랑 TLB의 page#가 다르거나 valid가 0 이면,
우선 page table로 가서 frame# 있나 확인한다. (page table엔 valid frame#만)
있다면, 가상페이지가 ram에 올라와있는거다.
없다면 page fault ( 가상 메모리에 매핑된 실제 frame#가 physical memory에 안 올라와있다.) os 가 디스크에서 해당 가상 페이지를 찾아 Ram의 빈 프레임에 올려둔다.
page table에 적고 valid bit을 1로 적고, TLB를 업데이트하며 valid bit은 1로

가상 메모리를 사용하는 이유는 프로세서가 컴퓨터의 모든 메모리를 전부 사용하고 있다는 착각이 들게 하기 위함 물리적 메모리 ram의 한계를 넘어선듯이 작동
이때 가상 메모리는 '페이지'라는 고정 크기로 관리됨 (4kb) - '프레임'이라는 물리적 메모리 단위랑 매핑
페이지 테이블엔 프레임 번호와 VALID 값이 있다.
VALID 값이 1이면 physical memory(ram)에 존재하지만, 0 이면 페이지 fault 발생해서 os가보조메모리(disk storage)에서 해당 페이지를 찾는다.
그 후 os 물리적 메모리 ram에 빈 프레임을 찾고 페이지를 프레임에 로드한다.
그 후 os 가 페이지 테이블을 업데이트한다. 

하드웨어는 각 프로세스마다 페이지 테이블이 있고, 각 프로세스마다 가상 메모리 공간을 갖는다. 페이지 테이블은 메모리 관리 유닛(MMU)에 의해 관리
cpu 즉 complier는 logical address를 요청한다. 실제 올라가는 주소 모른다. 

프로세스가 요청하는 메모리 크기를 페이지 단위로 구분한다. 

##### valid 가 1이다의 의미?
0 이면 page fault 다 => 프로그램이 접근하려는 데이터가 ram 에 없는 경우
page fault 가 발생하면, disk storage 의 virtual memory에 있는 가상 주소를 ram에 올리고 os가 페이지 테이블을 vaild 1 이랑 frame# 적어서 수정한다. 

그럼 프로그램 시작할때 보조 메모리에서 ram으로 데이터 올리고 시작하는데 이때 페이지 테이블도 수정하는건가??